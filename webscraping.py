# -*- coding: utf-8 -*-
"""WebScraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17z_whAcV6D33ShgRhAEhRag3f4bqUcMv

# Web Scraping

* Scraping consiste em uma aplicação capaz de consultar um servidor web, solicitar dados, analisar e extrair as informações necessárias.
* A prática de Web Scraping normalmente é uma solução quando não há outras maneiras de coletar dados necessários a um projeto, mas em muitos casos também é a prática de acelerar um processo que antes era feito manualmente.
* Muitas vezes bases de dados públicos não estão disponíveis para serem consumidas, entretanto os dados estão disponíveis por meio de acesso às páginas Web, o Scraping funciona muito bem para esse tipo de proposta.
* Lembre-se sempre que com a LGPD a coleta de dados é
sempre algo que precisa ser pensado com muito cuidado.
Nem todo dado que está público pode ser consumido e
utilizado (como por exemplo os preços de um e-commerce)
* Ao pensar em Scraping, imagine um conjunto de dados que precisa coletar e juntar, e que um "robozinho" vai fazer isso pra você. Ahhh, e o robozinho é você quem vai fazer!!

## Biblioteca BeautifulSoup

*   A biblioteca BeautifulSoup para Python, é uma das bibliotecas mais utilizadas para fazer web scraping.
*   Há muitas outras bibliotecas para scraping, como **Selenium** e **Scrapy**, que também têm funcionalidades parecidas. Cada uma delas tem suas vantagens e desvantagens, entretanto uma grande vantagem entre elas é que a lógica de pensamento para operá-las tem alguma similaridade.
*   A biblioteca **BeautifulSoup** constrói uma árvore a partir de vários elementos de uma página e fornece uma interface simples para acessá-los.

Para poder utilizar a biblioteca BeautifulSoup vamos precisar da ajuda da **biblioteca Requests** e de um **parseador html**.

## Importar as Bibliotecas
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

"""## Vamos dar uma olhada na página que vamos fazer scraping"""



"""https://statisticstimes.com/tech/top-computer-languages.php

## Vamos coletar a página
"""

html = requests.get("https://statisticstimes.com/tech/top-computer-languages.php").text
soup = BeautifulSoup(html, 'html5lib')

"""## Encontrar o primeiro parágrafo


"""

# estou mandando procurar a tag P e colocar na variável primeiro_paragrafo
primeiro_paragrafo = soup.find('p')
primeiro_paragrafo

primeiro_paragrafo.text

"""## Pegar todos os parágrafos (função find_all)"""

# find_all puxa uma lista com todos os parágrafos do site
todos_paragrafos = soup.find_all('p')
todos_paragrafos

todos_paragrafos[0]

"""## Agora vamos pegar todos os links"""

todos_links = soup.find_all('a')
todos_links

"""## Vamos inspecionar a tabela para pegar os dados da tabela "PLP Index (Worldwide)"
"""

tabela = soup.find('table', {'id': 'table_id1'}).find('tbody')
tabela

linhas = tabela.find_all('tr')

for linha in linhas:
  dado = linha.find_all('td')
  print(dado[0].text)
  print(dado[2].text)
  print(dado[3].text)
  print('-----')

"""## Montar uma lista de linguagens e de porcentagem com os dados, para depois compor um dataframe"""

linguagem = []
pontos = []

for linha in linhas:
  dado = linha.find_all('td')
  linguagem.append(dado[2].text)
  pontos.append(dado[3].text)

print(linguagem)
print(pontos)

dados = pd.DataFrame(linguagem, columns = ['Linguagem'])
dados['Pontos'] = pontos
dados